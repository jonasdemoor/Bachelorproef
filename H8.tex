
%%=============================================================================
%% H8 - Performantieverschillen bij verschillende types RAID-opstellingen
%%=============================================================================

\chapter{Benchmarking van RAID-types}
\label{ch:h8}

In dit hoofdstuk wordt de performantie van twee types RAID, namelijk ZFS RAID-Z en Linux MD (een softwarematige RAID voor Linux) gemeten en met elkaar vegeleken.

\section{Toelichting van de gehanteerde methodiek}

Vooraleer over te gaan tot de testen, worden de gehanteerde tools, methodes en maatstaven wat meer toegelicht. Zoals reeds gezegd in de inleiding van deze scriptie, zal er vooral worden rekening worden gehouden met het aantal invoer- en uitvoerbewerkingen per seconde (of IOPS in het Engels). Daarnaast worden enkele workloads gesimuleerd op het testsysteem met name die van een databank en die van een webserver.  

Voor het uitvoeren van de testen wordt er gebruik gemaakt van \textbf{Phoronix Test Suite\footnote{\url{https://www.phoronix-test-suite.com}}}: deze suite is een wrapper rond veelgebruike benchmarktools en maakt het mogelijk om op een makkelijke manier relevante gegevens te verzamelen. Er is weinig tot geen voorafgaande kennis vereist voor het uitvoeren van de verschillende benchmarks, en dit was dan ook één van de hoofdredenen om voor dit programma te kiezen. 

Eerst werden er twee algemene testen uitgevoerd, nl. FIO (Flexible I/O Tester) en FS-Mark; deze maten respectievelijk het aantal IOPS van de RAID-opstellingen en de algemene performance van de bestandssystemen bovenop deze RAID-opstellingen. Daarna werden twee types workloads,nl. een databanksysteem en een webserver, gesimuleerd; deze simulaties werden uitgevoerd met behulp van de SQLite benchmark en de PostMark benchmark.

Op de MD-RAID-opstellingen werd telkens XFS gebruikt als bestandssysteem; dit omdat XFS zich in de meeste gevallen automatisch aanpast aan de omstandigheden en er dus weinig tot geen optimalisatie nodig is \autocite{XFSCommunity2016}. Bij een RAID1-opstelling werden altijd de eerste twee schijven gebruikt.

\section{Benchmarks: resultaten \& bevindingen}

In deze sectie worden de uitgevoerde testen en diens resultaten toegelicht en besproken.

\subsection{FIO: Flexible I/O Tester}

Bij testen met een blokgrootte van 4KB waren er grote verschillen op te merken tussen MD-RAID en ZFS RAID; daarom werd er een extra test uitgevoerd waarbij de blokgrootte 4MB bedroeg. 

\subsubsection{FIO met een blokgrootte van 4KB}

\begin{table}[h]
  \centering
  \begin{tabular}{l || c c c c | c c c c}
    \hline
    \multicolumn{9}{c}{\textbf{Flexible I/O Tester (blokgrootte: 4KB)}} \\
    \hline
    & \multicolumn{4}{c|}{\textbf{ZFS}} & \multicolumn{4}{|c}{\textbf{Linux MD (XFS)}} \\
    & RR & RW & SR & SW & RR & RW & SR & SW \\
    \hline
    RAID0 (Stripe) & 91924 & 4318 & 298431 & 82261 & 161 & 233812 & 100500  & 117097  \\
    RAID1 (Mirror) & 88476 & 1816 & 302429 & 32570 & 120 & 142855 & 35124  & 104094 \\
    RAID5 (RAID-Z) & 89730 & 3164 & 303172 & 61885 & 127 & 44623 & 51440  & 53907 \\
  \end{tabular}
  \caption{Resultaten van de FIO-benchmark (blokgrootte: 4KB) in IOPS. RR, RW, SR en SW staan respectievelijk voor Random Read, Random Write, Sequential Read en Sequential Write (hoe meer, hoe beter)}
  \label{tab:results_fio_4k}
\end{table}

Uit de resultaten kan worden afegeleid dat beide RAID-types elk uitblinken in bepaalde soorten operaties. ZFS RAID behaalt in het algemeen erg goede resultaten bij random read bewerkingen en bij sequential reads; Linux MD haalt dan echter weer goede scores bij random writes en sequential writes. Theoretisch gezien zou Linux MD dus beter geschikt moeten zijn voor bijvoorbeeld databankoperaties, waarbij veel random writes voorkomen. ZFS zou theoretisch gezien beter zijn in het uitlezen van groten samenhangende bestanden (zoals back-ups of videobestanden), waarbij hoofdzakelijk sequential reads nodig zijn.  

\subsubsection{FIO met een blokgrootte van 4MB}

\begin{table}[h]
  \centering
  \begin{tabular}{l || c c c c | c c c c}
    \hline
    \multicolumn{9}{c}{\textbf{Flexible I/O Tester (blokgrootte: 4MB)}} \\
    \hline
    & \multicolumn{4}{c|}{\textbf{ZFS}} & \multicolumn{4}{|c}{\textbf{Linux MD (XFS)}} \\
    & RR & RW & SR & SW & RR & RW & SR & SW \\
    \hline
    RAID0 (Stripe) & 548 & 79 & 561 & 80 & 41 & 276 & 97 & 99 \\
    RAID1 (Mirror) & 560 & 31 & 575 & 31 & 26 & 100 & 33 & 111 \\
    RAID5 (RAID-Z) & 568 & 61 & 571 & 61 & 32 & 51 & 62 & 51 \\
  \end{tabular}
  \caption{Resultaten van de FIO-benchmark (blokgrootte: 4MB) in IOPS. RR, RW, SR en SW staan respectievelijk voor Random Read, Random Write, Sequential Read en Sequential Write (hoe meer, hoe beter)}
  \label{tab:results_fio_4mb}
\end{table}

Het verhogen van de blocksize van de testen veranderde nauwelijks iets aan de conclusies die konden getrokken worden uit de voorgaande testen; de verhoudingen komen nagenoeg overeen. Echter is het contrast tussen ZFS en MDADM bij de hierbovengenoemde operaties veel duidelijker geworden door het optrekken van de blokgrootte. 

Bij beide blocksizes kan worden opgemerkt dat RAID5 vaak het laagste aantal IOPS heeft. Dit is normaal, aangezien de parity ook nog moet berekend worden (zie Hoofstuk \ref{ch:h2}).

\subsection{FS-Mark}

Als test case werd er telkens gekozen voor de vierde optie, nl. het uitvoeren van een test met 40000 bestanden van elk 1MB groot en met een diepte van 32 mappen. 

\begin{table}[h]
  \centering
  \begin{tabular}{l || c | c }
    \hline
    \multicolumn{3}{c}{\textbf{FS-Mark (4000 bestanden, 32 submappen, bestandsgrootte: 1MB)}} \\
    \hline
    & \textbf{ZFS} & \textbf{Linux MD (XFS)} \\
    \hline
    RAID0 (Stripe) & 44.87 & 26.13 \\
    RAID1 (Mirror) & 22.97 & 21.82 \\
    RAID5 (RAID-Z) & 32.43 & 12.28 \\
  \end{tabular}
  \caption{Resultaten van de FS-Mark-benchmark (4000 bestanden, 32 submappen, bestandsgrootte: 1MB) in bestanden/s (hoe meer, hoe beter)}
  \label{tab:results_fmark}
\end{table}

Bij deze benchmark komt ZFS als beste uit de bus; enkel de prestaties bij RAID1 zijn bijna gelijk. De verklaring van de goede performantie bij een ZFS stripe en RAID-Z kan worden gevonden bij de variabele blokgrootte die ZFS hanteert (zie Hoofdstuk \ref{ch:h4} en bij de uitgebreide cachingmogelijkheden, waar ZFS gretig gebruik van maakt. 

\subsection{SQLite}

Bij deze benchmark wordt er een groot aantal \texttt{INSERT}-bewerkingen gedaan op een SQLite-database; hier wordt dus vooral de random write performantie getest.

\begin{table}[h]
  \centering
  \begin{tabular}{l || c | c }
    \hline
    \multicolumn{3}{c}{\textbf{SQLite}} \\
    \hline
    & \textbf{ZFS} & \textbf{Linux MD (XFS)} \\
    \hline
    RAID0 (Stripe) & 154.36 & 295.50 \\
    RAID1 (Mirror) & 230.29 & 444.29 \\
    RAID5 (RAID-Z) & 273.47 & 476.32 \\
  \end{tabular}
  \caption{Resultaten van de SQLite-benchmark in seconden (hoe minder, hoe beter)}
  \label{tab:results_sqlite}
\end{table}

Bij deze databasesimulatie is het verschil in performantie tussen ZFS en Linux MD erg groot, nl. ongeveer 200 seconden. Opnieuw kan dit verklaard worden aan de hand van het cachingmechanisme van ZFS: ZFS gaat zoveel mogelijk data cachen, en rapporteert vervolgens aan de applicatie (in dit geval SQLite) dat de transactie voltooid is (terwijl dit niet noodzakelijk zo hoeft te zijn). Een andere mogelijke factor kan de relatief grootte blokgrootte van XFS zijn in vergelijking met de variabele blokgrootte van ZFS.

\subsection{PostMark}

Deze test verricht een aantal transacties op de RAID-array: op deze manier wordt de werking van een mail- of webserver gesimuleerd.

\begin{table}[h]
  \centering
  \begin{tabular}{l || c | c }
    \hline
    \multicolumn{3}{c}{\textbf{PostMark}} \\
    \hline
    & \textbf{ZFS} & \textbf{Linux MD (XFS)} \\
    \hline
    RAID0 (Stripe) & 3488 & 2988 \\
    RAID1 (Mirror) & 3099 & 3112 \\
    RAID5 (RAID-Z) & 3260 & 2787 \\
  \end{tabular}
  \caption{Resultaten van de PostMark-benchmark in transacties/s (hoe meer, hoe beter)}
  \label{tab:results_postmark}
\end{table}

De resultaten van deze benchmark wijken niet zo sterk af van elkaar. Toch is het opmerkelijk dat beide RAID-types bijna hetzelfde aantal transacties kunnen verwerken bij RAID-niveau 1, aangezien er bij andere RAID-niveaus relatief grote verschillen zijn.
